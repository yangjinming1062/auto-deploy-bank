services:
  diffir-inference:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: diffir-service
    ports:
      - "40426:8080"
    environment:
      - PORT=8080
      - PYTHONUNBUFFERED=1
      - PYTHONPATH=/home/ubuntu/deploy-projects/6127593a9944c99237f21d2d
      # PyTorch distributed training environment variables
      - RANK=0
      - WORLD_SIZE=1
      - LOCAL_RANK=0
      - MASTER_ADDR=127.0.0.1
      - MASTER_PORT=29500
      # GPU configuration (empty means use CPU, set GPU devices with CUDA_VISIBLE_DEVICES)
      - CUDA_VISIBLE_DEVICES=
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 1G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 30s
      retries: 3
      start_period: 10s
    restart: unless-stopped