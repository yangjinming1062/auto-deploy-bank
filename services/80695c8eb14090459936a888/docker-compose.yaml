services:
  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: codefuse-chatbot-api
    ports:
      - "40792:7861"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - API_BASE_URL=${API_BASE_URL:-https://api.openai.com/v1}
      - EMBEDDING_ENGINE=${EMBEDDING_ENGINE:-model}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-}
      - LLM_MODEL=${LLM_MODEL:-}
      - DOCKER_SERVICE=false
      - SANDBOX_DO_REMOTE=false
      - log_verbose=false
    volumes:
      - ./data:/home/ubuntu/deploy-projects/80695c8eb14090459936a888/data
      - ./logs:/home/ubuntu/deploy-projects/80695c8eb14090459936a888/logs
      - ./jupyter_work:/home/ubuntu/deploy-projects/80695c8eb14090459936a888/jupyter_work
      - ./nltk_data:/home/ubuntu/deploy-projects/80695c8eb14090459936a888/nltk_data
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 1G
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7861/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s