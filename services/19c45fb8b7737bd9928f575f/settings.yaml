# GraphRAG Configuration File
# Copy this to your working directory as settings.yaml

# Application name
name: "graphrag-app"

# Logging configuration
logging:
  directory: "output/logs"
  filename: "app.log"

# LLM Configuration
# Define completion models (used for text generation)
completion_models:
  default_completion_model:
    model_provider: "openai"  # or "azure"
    api_key: ${GRAPHRAG_API_KEY}
    api_base: ${GRAPHRAG_API_BASE}
    api_version: "2024-02-15-preview"
    model: "gpt-4"
    max_tokens: 4000
    temperature: 0

# Embedding models (used for vector search)
embedding_models:
  default_embedding_model:
    model_provider: "openai"  # or "azure"
    api_key: ${GRAPHRAG_API_KEY}
    api_base: ${GRAPHRAG_API_BASE}
    api_version: "2024-02-15-preview"
    model: "text-embedding-3-large"
    max_tokens: 8192

# Vector store configuration
vector_store:
  type: "lancedb"  # Options: lancedb, azure_ai_search, cosmosdb
  db_uri: "output/lancedb"

# Input configuration
input:
  type: "text"  # Options: text, csv, blob
  file_pattern: "*.txt"
  base_dir: "input"

# Storage configuration
storage:
  type: "file"  # Options: file, memory, blob, cosmosdb
  base_dir: "output"

# Cache configuration
cache:
  type: "json"
  base_dir: "cache"

# Community reports configuration
community_reports:
  max_length: 2000
  max_input_length: 8000

# Snapshots configuration
snapshots:
  embeddings: false
  graphml: false
  raw_graph: false