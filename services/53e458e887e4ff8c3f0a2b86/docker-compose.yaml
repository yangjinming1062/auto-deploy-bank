services:
  langgraph4j-studio:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: langgraph4j-studio
    ports:
      - "40438:8080"
    environment:
      - SERVER_PORT=8080
      - SERVER_SERVLET_CONTEXT_PATH=/studio/v1
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - TAVILY_API_KEY=${TAVILY_API_KEY:-}
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 1G
    volumes:
      - ./target.jar:/app/target.jar
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/studio/v1/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s