services:
  gradio-app:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "40576:7860"
    environment:
      - LLM_BASE_URL=${LLM_BASE_URL:-}
      - LLM_API_KEY=${LLM_API_KEY:-sk-}
      - LLM_MODEL=${LLM_MODEL:-gpt-4o}
      - LLM_MAX_TOKEN=${LLM_MAX_TOKEN:-1500}
      - LLM_REQUEST_TIMEOUT=${LLM_REQUEST_TIMEOUT:-500}
      - LANGCHAIN_TRACING_V2=${LANGCHAIN_TRACING_V2:-false}
      - LANGCHAIN_ENDPOINT=${LANGCHAIN_ENDPOINT:-https://api.smith.langchain.com}
      - LANGCHAIN_API_KEY=${LANGCHAIN_API_KEY:-lsv2_}
      - LANGCHAIN_PROJECT=${LANGCHAIN_PROJECT:-xxx}
      - Neo4j_URI=neo4j://neo4j:7687
      - PINECONE_API_KEY=${PINECONE_API_KEY:-pcsk_}
      - Feature_URI=${FEATURE_URI:-http://image-embedding:8001}
      - Omni_URI=${OMNI_URI:-http://omni-parser:8000}
    depends_on:
      neo4j:
        condition: service_started
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 1G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7860/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    restart: unless-stopped

  neo4j:
    image: neo4j:5.18.1
    environment:
      - NEO4J_AUTH=neo4j/12345678
      - NEO4J_PLUGINS=["apoc"]
      - HEAP_SIZE=512m
      - PAGE_CACHE_SIZE=128m
    healthcheck:
      test: ["CMD-SHELL", "curl -s -f http://localhost:7474/ || exit 1"]
      interval: 10s
      timeout: 10s
      retries: 30
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 4G
        reservations:
          cpus: '0.5'
          memory: 2G
    restart: unless-stopped
    volumes:
      - neo4j_data:/data

# Optional backend services (require GPU)
# Uncomment if GPU is available
# image-embedding:
#   build:
#     context: ./backend/ImageEmbedding
#     dockerfile: Dockerfile
#   ports:
#     - "8001:8001"
#   volumes:
#     - ./backend/ImageEmbedding:/app
#   deploy:
#     resources:
#       reservations:
#         devices:
#           - driver: nvidia
#             count: 1
#             capabilities: [ gpu ]
#   restart: unless-stopped

# omni-parser:
#   build:
#     context: ./backend/OmniParser
#     dockerfile: Dockerfile
#   ports:
#     - "8000:8000"
#   volumes:
#     - ./backend/OmniParser:/app
#     - ./backend/OmniParser/weights:/app/weights
#   deploy:
#     resources:
#       reservations:
#         devices:
#           - driver: nvidia
#             count: 1
#             capabilities: [ gpu ]
#   restart: unless-stopped

networks:
  default:
    name: app-network

volumes:
  neo4j_data:
    driver: local